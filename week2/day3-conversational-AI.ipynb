{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "766f8920",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from dotenv import load_dotenv\n",
        "from openai import OpenAI\n",
        "import gradio as gr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "16e78c80",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# A Funny Fact About Kenya ðŸ¦\n",
            "\n",
            "Kenya is home to the **Giraffe Centre in Nairobi**, where you can hand-feed giraffes that are taller than buildingsâ€”and they'll eat food right out of your hand with their 20-inch tongues. \n",
            "\n",
            "The funny part? Visitors often describe it as strangely intimate and awkward having a massive, gentle giant delicately lick your palm. Some people say it feels like being kissed by an alien with a 6-foot-long tongue! ðŸ˜„\n",
            "\n",
            "**Bonus funny fact:** Kenya has a desert that's inexplicably lush and greenâ€”it's called **Turkana Lake** and is located in one of the hottest, driest regions of the country, earning it the nickname \"the Jade Sea.\" It's basically nature's practical joke.\n",
            "\n",
            "Would you like to know more about Kenya's wildlife or culture?\n"
          ]
        }
      ],
      "source": [
        "load_dotenv(override=True)\n",
        "\n",
        "openrouter_api_key = os.getenv(\"OPENROUTER_API_KEY\")\n",
        "base_url = \"https://openrouter.ai/api/v1\"\n",
        "openai = OpenAI(api_key=openrouter_api_key, base_url=base_url)\n",
        "\n",
        "\n",
        "messages = [\n",
        "    {\"role\": \"system\", \"content\": \"You are a helpful assistant that can answer questions and help with tasks.\"},\n",
        "    {\"role\": \"user\", \"content\": \"Funny fact about kenya\"}\n",
        "]\n",
        "\n",
        "response = openai.chat.completions.create(\n",
        "    model=\"anthropic/claude-haiku-4-5\",\n",
        "    messages=messages\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0f9ad0a0",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "4f738ded",
      "metadata": {},
      "source": [
        "### Simple chat bot that keeps conversation History"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bffce91f",
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def chat(message, history):\n",
        "\n",
        "    print(\"message is:\", message)\n",
        "    print(\"history is:\", history)\n",
        "    system_message = \"\"\"You are a helpful assistant in a clothes store. You should try to gently encourage \\\n",
        "                        the customer to try items that are on sale. Hats are 60% off, and most other items are 50% off. \\\n",
        "                        For example, if the customer says 'I'm looking to buy a hat', \\\n",
        "                        you could reply something like, 'Wonderful - we have lots of hats - including several that are part of our sales event e.g.,Kofia and Godfather.'\\\n",
        "                        Encourage the customer to buy hats if they are unsure what to get.\n",
        "                        \"\"\"\n",
        "    history = [{\"role\":h[\"role\"], \"content\":h[\"content\"]} for h in history]\n",
        "    messages = [{\"role\": \"system\", \"content\": system_message}] + history + [{\"role\": \"user\", \"content\": message}]\n",
        "    response = openai.chat.completions.create(model=\"gpt-4.1-mini\", messages=messages)\n",
        "    return response.choices[0].message.content\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4de8e7e1",
      "metadata": {},
      "outputs": [],
      "source": [
        "gr.ChatInterface(fn=chat).launch()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2c970f46",
      "metadata": {},
      "source": [
        "### Using yield to ensure proper streaming"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4c110c34",
      "metadata": {},
      "outputs": [],
      "source": [
        "system_message = \"\"\"You are a helpful assistant in a clothes store. You should try to gently encourage \\\n",
        "                        the customer to try items that are on sale. Hats are 60% off, and most other items are 50% off. \\\n",
        "                        For example, if the customer says 'I'm looking to buy a hat', \\\n",
        "                        you could reply something like, 'Wonderful - we have lots of hats - including several that are part of our sales event e.g.,Kofia and Godfather.'\\\n",
        "                        Encourage the customer to buy hats if they are unsure what to get.\n",
        "                        \"\"\"\n",
        "def chat(message, history):\n",
        "    history = [{\"role\":h[\"role\"], \"content\":h[\"content\"]} for h in history]\n",
        "    relevant_system_message = system_message\n",
        "    if 'belt' in message.lower():\n",
        "        relevant_system_message += \" The store does not sell belts; if you are asked for belts, be sure to point out other items on sale.\"\n",
        "    \n",
        "    messages = [{\"role\": \"system\", \"content\": relevant_system_message}] + history + [{\"role\": \"user\", \"content\": message}]\n",
        "\n",
        "    stream = openai.chat.completions.create(model=\"anthropic/claude-haiku-4-5\", messages=messages, stream=True)\n",
        "\n",
        "    response = \"\"\n",
        "    for chunk in stream:\n",
        "        response += chunk.choices[0].delta.content or ''\n",
        "        yield response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "366f381a",
      "metadata": {},
      "outputs": [],
      "source": [
        "gr.ChatInterface(fn=chat).launch()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ef57c6a9",
      "metadata": {},
      "source": [
        "### An implementation to help visualiza entire conversation so far"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "42821b4c",
      "metadata": {},
      "outputs": [],
      "source": [
        "import gradio as gr\n",
        "\n",
        "\n",
        "def history_to_markdown(history) -> str:\n",
        "    \"\"\"Render Gradio chat history into a readable transcript.\"\"\"\n",
        "    if not history:\n",
        "        return \"_No conversation yet._\"\n",
        "\n",
        "    lines = [\"## Conversation history\\n\"]\n",
        "\n",
        "    # Gradio may store history as either:\n",
        "    # - messages format: [{\"role\": \"user\"|\"assistant\", \"content\": \"...\"}, ...]\n",
        "    # - tuples format: [(user, assistant), ...]\n",
        "\n",
        "    if history and isinstance(history[0], dict):\n",
        "        for msg in history:\n",
        "            role = str(msg.get(\"role\", \"\")).strip() or \"message\"\n",
        "            content = \"\" if msg.get(\"content\") is None else str(msg.get(\"content\"))\n",
        "            lines.append(f\"- **{role}**: {content}\")\n",
        "        return \"\\n\".join(lines)\n",
        "\n",
        "    for i, turn in enumerate(history, start=1):\n",
        "        if isinstance(turn, (list, tuple)) and len(turn) == 2:\n",
        "            user_msg, assistant_msg = turn\n",
        "            user_msg = \"\" if user_msg is None else str(user_msg)\n",
        "            assistant_msg = \"\" if assistant_msg is None else str(assistant_msg)\n",
        "            lines.append(f\"### Turn {i}\\n**User:** {user_msg}\\n\\n**Assistant:** {assistant_msg}\\n\")\n",
        "        else:\n",
        "            lines.append(f\"- {turn}\")\n",
        "\n",
        "    return \"\\n\".join(lines)\n",
        "\n",
        "\n",
        "def respond(message: str, history):\n",
        "    if not (message or \"\").strip():\n",
        "        return \"\", history, history_to_markdown(history)\n",
        "\n",
        "    if \"openai\" not in globals() or openai is None:\n",
        "        raise gr.Error(\"OpenAI/OpenRouter client not initialized. Run the earlier setup cell first.\")\n",
        "\n",
        "    relevant_system_message = system_message\n",
        "    if \"belt\" in message.lower():\n",
        "        relevant_system_message += (\n",
        "            \" The store does not sell belts; if asked for belts, suggest other items on sale instead.\"\n",
        "        )\n",
        "\n",
        "    messages = [{\"role\": \"system\", \"content\": relevant_system_message}]\n",
        "\n",
        "    history = history or []\n",
        "\n",
        "    # Normalize history into messages format for both Gradio + OpenAI\n",
        "    normalized_history = []\n",
        "    if history and isinstance(history[0], dict):\n",
        "        normalized_history = [\n",
        "            {\"role\": str(m.get(\"role\", \"\")), \"content\": \"\" if m.get(\"content\") is None else str(m.get(\"content\"))}\n",
        "            for m in history\n",
        "        ]\n",
        "    else:\n",
        "        for user_msg, assistant_msg in history:\n",
        "            if user_msg is not None and str(user_msg).strip() != \"\":\n",
        "                normalized_history.append({\"role\": \"user\", \"content\": str(user_msg)})\n",
        "            if assistant_msg is not None and str(assistant_msg).strip() != \"\":\n",
        "                normalized_history.append({\"role\": \"assistant\", \"content\": str(assistant_msg)})\n",
        "\n",
        "    messages.extend(normalized_history)\n",
        "    messages.append({\"role\": \"user\", \"content\": message})\n",
        "\n",
        "    response = openai.chat.completions.create(\n",
        "        model=\"anthropic/claude-haiku-4-5\",\n",
        "        messages=messages,\n",
        "    )\n",
        "    assistant = response.choices[0].message.content\n",
        "\n",
        "    new_history = normalized_history + [\n",
        "        {\"role\": \"user\", \"content\": message},\n",
        "        {\"role\": \"assistant\", \"content\": assistant},\n",
        "    ]\n",
        "\n",
        "    return \"\", new_history, history_to_markdown(new_history)\n",
        "\n",
        "\n",
        "with gr.Blocks(title=\"Conversational AI (with transcript)\") as demo:\n",
        "    gr.Markdown(\"## Clothes store assistant\\nChat below, then click **View conversation history** to see the full transcript.\")\n",
        "\n",
        "    try:\n",
        "        chatbot = gr.Chatbot(label=\"Chat\", type=\"messages\")\n",
        "    except TypeError:\n",
        "        chatbot = gr.Chatbot(label=\"Chat\")\n",
        "\n",
        "    with gr.Row():\n",
        "        msg = gr.Textbox(label=\"Message\", placeholder=\"Ask about hats, shirts, etc.\")\n",
        "\n",
        "    with gr.Row():\n",
        "        send = gr.Button(\"Send\", variant=\"primary\")\n",
        "        view = gr.Button(\"View conversation history\")\n",
        "        clear = gr.Button(\"Clear\")\n",
        "\n",
        "    transcript = gr.Markdown(label=\"Transcript\")\n",
        "\n",
        "    send.click(respond, inputs=[msg, chatbot], outputs=[msg, chatbot, transcript])\n",
        "    msg.submit(respond, inputs=[msg, chatbot], outputs=[msg, chatbot, transcript])\n",
        "    view.click(history_to_markdown, inputs=[chatbot], outputs=[transcript])\n",
        "    clear.click(lambda: ([], \"\", \"_No conversation yet._\"), outputs=[chatbot, msg, transcript])\n",
        "\n",
        "demo.launch()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "llms",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
